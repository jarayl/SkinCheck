# Design

# Design Goal
The goal of this project was to integrate a machine learning model that recognized malignant skin lesions with a telehealthcare website.

This website contains two sides which are integrated with each other through a common database. The first side of the website is for users who are doctors. It uses its own HTML layout page which all other doctor-specific pages extend with Jinja. The second side of the website is for users who are patients. It too has its own HTML layout page which all patient-specific pages extend with Jinja. While both HTML layout pages maintain similar color schemes, styling of elements, and structure for the sake of homogeneity throughout the website as a whole, they differ in the navigation bar: the doctor navigation bar only navigates to routes of the form “/doctor/…”, and the patient navigation bar similarly only navigates to routes of the form “patient/…”. We chose this design to maintain clarity in our code and website: patient-side webpages had routes associated only with patients, and doctor-side webpages had routes associated only with doctors. It is important to note that we took inspiration for our navigation bar from CS50 Finance.

# # Helper Decorators
In order to prevent a user from accessing the other side of the website (by typing “/doctor/…” or “/patient/…” in the URL), we made use of decorator functions. We drew inspiration for these helper functions from CS50 Finance. We implemented three decorator functions: login_required, doctor_only, and patient_only. These checked the session variables and redirected the user back to the initial index page if they were not logged in or were on the incorrect side of the website. Furthermore, by calling session.clear() in the index route, we effectively log the user out. Thus, a doctor user cannot access any patient web pages, and a patient user cannot access any doctor web pages. We implemented this design choice to improve the security of our website: it is crucial that a patient is not able to change the URL and access other patient records. Moreover, we chose to use decorator functions to achieve this in order to maintain the clarity of our code and reduce the amount of code we had to write– instead of writing if statements and redirect statements for every route, which would convolute our code, we could include a simply @doctor_only decorator above the function associated with a given route to accomplish the same task. 

# # Database Configuration
In order to integrate the two sides of the website together, we used a common SQLite database which stored data for both the doctor and patient side of the website. Since the goal of this final project was to take off the “training wheels” provided by CS50 and develop a project as we would on our own, we steered away from any CS50 provided assistance. Thus, we chose to use the sqlite3 module in python to handle all database interactions and developed the entirety of the project in native VSCode instead of the CS50 IDE. This proved to be a challenge, however, as database interactions using sqlite3 are significantly more complex than database interactions with CS50’s provided SQL library. Furthermore, developing a web application in native VSCode was more challenging than anticipated since we needed to set up a virtual environment.

In our SQLite database, we created four tables: a patients table containing all information stored for a patient user (including a unique patientIDand patient email), a doctors table containing all information stored for a doctor user (including a unique doctorID and unique doctor email), a doctor-patient relationship table storing a doctorID and patientID together, and a data table containing information outputted by our machine learning model (as well as the associated doctor id, patient id, and data id). We chose to store unique emails for both doctors and patients since we know that most real-world applications do not allow different users to share emails. Moreover, by storing the unique email, the user has unique identification for themselves: while a user does not know theID we assign them in either the patient or doctor table, they know their own email. We chose to design our backend this way in order to organize our data in a way that simplified SQLite interactions. For instance, registering a new doctor user or patient user would amount to getting the input submitted via a post request by the user and simply inserting that information into the respective table (after sanitizing and validating the input). Logging in would function by querying the respective table. Furthermore, by creating a table just for doctor-patient relationships, finding all patients of a doctor or finding all doctors that a patient has is trivial. Finally, by storing the patient id, doctor id, and unique dataID in the data table, accessing an entire patient’s history or a single diagnosis is trivial through a SQLite query. In structuring our database this way, we found a balance between minimizing the number of table joins in SQL queries while creating a clear and organized way in which we could visualize our backend.


# # Website
Upon launching the SkinCheck application, the user is brought to the index page where they are presented with three buttons. The first of which is the “Learn More” button, which navigates the user to the about us route. This is the only route in the app which is not decorated with any of the helper functions– thus, it is available to users as soon as they launch the app. The other two buttons are used to determine which side of the website the user will interact with: depending on which button the user clicks, the index page will submit the type of user (either Doctor or Patient) via post and redirect them to the respective login screens through an if else statement. Furthermore, the type of user is stored in a session variable. Thus, we can access this session variable in our helper decorator functions, restricting access to some routes in the website. We chose this design since doctors and patients must use different login and registration pages, so it follows logically that we first prompt the user for their user type. Finally, we include session.clear() in the beginning of the route function. Thus, if a user is just launching the website, their session variable is empty and their experience will not be affected. However, if they try to edit the URL and are redirected back to the index page, then their session is cleared and they are effectively logged out. 

# # Login/Register
Upon clicking either button, the user is redirected to their respective login page. Logging in and registration are very similar to the implementation in CS50 Finance. In both patients and doctors login pages, we used HTML forms to pass the user email and password via a post request. Since emails are unique in both the patients and doctors table, we queried through the respective tables and used the check_password_hash() function in order to uniquely identify a user. We used if statements to check if our queries were empty. If they were empty, the user did not exist in the database so we used flask flashing and re-rendered the login page with the added flashed message. If the password did not match the patient with the submitted email in the table, then we would flash another error message and re-render the login page again. If the queries returned the user, then we would store either the patientID or doctorID in a session variable which would effectively “log” the user in. Registering a new doctor or patient works in a similar manner. The doctor registration page requires the user to enter their name, email, password, and password confirmation. We used if statements to verify that the passwords matched and that the passwords contained at least 8 characters long and 1 number, providing a very rudimentary level of security. If all forms were submitted, then we used a SQL insert statement to insert a new row in the doctor table with the respective values. Patient registration was implemented similarly. Registering a new doctor or patient works in a similar manner. The patient registration page requires the user to enter their name, email, date of birth, sex, password, and password confirmation. We used if statements to verify that the passwords matched and that the passwords contained at least 8 characters long and 1 number, providing a very rudimentary level of security. We also used the datetime module to verify that the date of birth was in valid format through an if statement. If all forms were submitted, then we used a SQL insert statement to insert a new row in the patients table with the respective values. Note that we verified that all forms were submitted through server-side if statements and protected against SQL injection attacks by substituting variables with “?”. Moreover, we used try-except statements to verify that the user email was not already in the respective table: since we defined the column to be unique, inserting an email that already existed would throw a SQL error which would cause the page to re-render with a flashed error message. We specifically designed our patient table to include more information than the doctors table because we thought it would be more important that the doctor have access to detailed patient information than patients have access to detailed doctor information.


# # Home Pages
Upon either successful patient registration or login, the user's unique patient ID would be stored in session and the user would be redirected to the patient home page. We chose this as it is the easiest way to allow the user to stay logged in between pages. In the patient home page, we display a table similar to the table in CS50 Finance. Using a SQL query, we fetch the patient name from the patients table using the patientID stored in session. Thus, we could pass this to our template and have our website greet the patient as they logged in, which we thought would be an appreciated personal touch. Then, we use a slightly complex SQL query to query through the data table, searching for all entries where the patient ID is equal to the ID stored in session. Moreover, we join the doctors table and patients table onto the data table using the unique doctor ids and unique patient ids in order to fetch the doctor name, doctor id, diagnosis, date of diagnosis, doctors comments, data id, machine learning images for all entries in the data table which match the patient id. Using the result of this query, which is a list of dictionaries, we pass the result to our patient home HTML template where we display the information in table format. We utilized Jinja for statements and dictionary keys to display this information. We chose to use a table to organize the result of our query as we believed that a table efficiently organized the dense information into readable rows, similar to how the data is stored in our database. Furthermore, we chose to place this table in the patient home screen as we believed this was the most important feature of our website for patients: the ability to quickly and easily access medical records. In our patient home page, each entry in the “diagnosis” column is a HTML hyperlink which directs the user to a new route that is dynamically generated through “/patient/{{ data.id }}”. We chose to pass in the dataID that was passed into the patient home template so that the route contains the unique dataID necessary to access the respective data from the data table.


# # 
Upon clicking the hyperlink, the user is routed to a unique url with that data ID in the URL. Then, our diagnosis route function takes the data ID passed in and queries the data table to gather the column values of that specific row in the data table. Thus, we can display the relevant diagnosis, diagnosis date, doctors comments, and machine learning model images by passing in the data to a separate HTML page. We chose to implement this as we thought it would be valuable for the patient to have an option to see the images outputted by the machine learning model as part of their records. However, since the images would be difficult to format into the table, we decided to pass these to a new route with a template displaying the images and relevant information.

Upon either successful patient registration or login, the user's unique doctor ID would be stored in session and the user would be redirected to the patient home page. We also chose this as it is the easiest way to allow the user to stay logged in between pages. In the doctor home page, we display a table similar to the table in CS50 Finance and patient home page. However, unlike the patient table, we made the doctor home page display all of the doctor's patients instead of all diagnoses. We chose this design because we believed that a doctor would have multiple patients. If the table displayed each individual diagnosis, then the readability of the table would be reduced and the doctor would have to waste time perusing through the table to find a patient's medical history. Instead we used a SQL query to query through the doctor-patient relationship table to find all the IDs of the patients associated with the current doctor ID (stored in the session). We also joined the doctor-patient relationship table to the patients table so we could also gather relevant information stored in the patients table such as patient name, patient email, patient date of birth, patient sex, and their health status (either malignant or benign).  We chose to implement this design because we believed it would not be useful for a doctor to be able to see just the patient ID (which is purely for database purposes). Instead, the most critical health and contact information should be displayed in the table format. We passed the result of this query to the doctor page using Jinja and dictionary keys to display this in table format– thus, each row in the table would correspond to one patient of the doctor. Furthermore, similar to the patients table, each entry in the “status” column is a HTML hyperlink which directs the doctor to a new route that is dynamically generated through “/doctor/{{ patient ID }}”. We chose to pass in the respective patient ID from the table row so that the route contains the information necessary to access all entries relevant to the patient ID in the data table. Thus, we chose this design so that the doctor would have a hyperlink 

Upon clicking the hyperlink, the user is routed to a unique url with that patient ID in the URL. Then, our patient history route function takes the patient ID passed in and queries the data table for all entries where the patient ID is the patient ID passed in and the doctor ID is the current user ID stored in session. Passing the result of that query into an HTML template, we then displayed each entry in a row where we displayed the machine learning model images, diagnosis, date, comments, and a delete button. We designed the doctor home page this way so that there was a clear organizational structure to help the doctor take care of their patients: patients are listed in the doctor home page table and clicking on each patient status takes the doctor to the medical records between only that specific doctor and patient. Moreover, we chose to include a delete button next to each diagnosis row for instances when a doctor made an incorrect comment or did not believe what the model outputted. In that case, the HTML page passes the unique data ID back via post. Then, we used a SQL delete statement to delete that specific data entry from the data table (protected by a try-except statement to ensure no errors). We attempted to design our doctor page in a way that made managing multiple patients much easier, improving the care provided by the doctor.

Upon clicking the “upload” button on the navigation bar in the doctor home page, the user is brought to a screen which takes a file input (specifically image input). Upon clicking the upload button, the file is passed back via post to the route. Then, we load in our machine learning models and perform a series of data type conversions on the image passed in. We first convert the image file to a numpy array so that the model can make inferences on the image. Then, the model passes back two images (the original image and a gradient-weighted class activation map), the model prediction, and the model confidence. Then, we convert the numpy arrays back to PNG images before converting them into base64 strings so that they can be displayed in HTML and stored in our SQL database. Finally, we store the prediction, confidence, and two base64 strings into temporary session variables so that we can redirect the user to the next HTML page. We designed this upload function to be as simple as possible to reduce human error. Furthermore, we used if statements to ensure the input was a valid image to pass to our model. We chose to do these design features in order to account for human error, which could output invalid data or crash the website. Finally, we chose to store the model output in session variables since passing an base64 converted image as a redirect argument truncates the image, causing the image to be unable to be displayed in HTML. By storing them in session variables, we guarantee that the base64 image strings are not truncated.

After storing the model output in temporary session variables, we redirect the user to a new uploaded route, where we access those session variables again. We pass the model output to an HTML template which displays the two images, diagnosis, and confidence. Moreover, we provide a place to input a patient email and comments. Thus, upon submission, we can use the patient email to query through the patient table to gather the patientIDassociated with the email. Then, we can use the current session id, patient id, model output, current timestamp (using datetime module), and comment input to insert a new entry into the data table. We chose this upload flow to make it extremely intuitive for doctors to upload a new medical record into their patients medical record. Thus, we can hope to eliminate as much human error as possible. Furthermore, we utilized if statements to validate the doctors input and try-except statements to eliminate the possibility of an error crashing the website. We hope that by making the process for image uploading as easy as possible for the doctor, we can streamline patient healthcare.

Upon clicking the “add patient” button on the navigation bar in the doctor home page, the user is brought to a screen which takes an email input (specifically email input). Then, after validating the input, we query the patient table for the email that was submitted via post. If the query is empty, we flash an error message and re-render the HTML template. If the patient exists, then we gather the patient ID and insert a new entry into the doctor-patient relationship table via another SQL statement (thus “adding” a patient to a doctors client list). Again, we use try-except statements to ensure no SQL error crashes the website. Furthermore, we chose to validate the email input and use try-except statements to further account for user error. We purposefully designed our website to be as robust as possible.

Upon clicking the “drop patient” button on the navigation bar in the doctor home page, we query through the doctor-patient relationship table and gather all patient IDs where the doctor ID is equal to the current ID stored in session. We also join that query onto the patients table so that we can gather the respective patient names. Then, we pass the list of patient names into an HTML template which uses Jinja to add them as options in a select form. Thus, we design our drop patient page such that the doctor can only drop patients that he currently has, eliminating human error. Upon form submission, we get the value of the selected input (which is the patient id) and use a SQL delete statement to delete the entry in the doctor-patient relationship table where the doctor ID is the current ID stored in session and the patient ID matches the form submission. This is surrounded by a try-except statement to ensure that any SQL error does not crash the website.

Overall, our goal for the design of this website was to make every page as robust as possible by either eliminating the possibility of human error or reducing it drastically through error handling. Through this, we hope to make a robust and streamlined telehealth platform geared towards skin cancer patients. Now, we will discuss the machine learning aspect of this project. 


# Machine Learning

On the machine learning side of things, our procedure can be separated into 4 distinct phases: data preprocessing (1), model training (2), data analysis (3), and explainable AI (4).

# # Phase 1
Phase 1 began with finding a dataset to train our AI model on. Because reliable AI depends on reliable data, I wanted to ensure that our data came from a credible source. After reviewing different websites that traditionally host machine learning/data science datasets such as Kaggle, The Cancer Imaging Archive, and Grand Challenge, I located a dataset on Kaggle that contained 1197 patient images of malignant skin lesions and 1440 patient images of benign skin lesions. These images were derived from the International Skin Imaging Collaboration​ Archive. Because I performed all the ML for SkinCheck in Google Colab to access Google's high-end GPUs, I uploaded this dataset to Google Drive so I could import it into my notebook. It's also worth noting the hierarchy of this dataset folder. 80% of the images are reserved for training the model in a subfolder called "train", while the other 20% of the images are reserved for evaluating the model and are stored in a subfolder called "test". The idea is that by preventing the model from looking at the test images, those images will serve as an unbiased method to test if the model has learned to generalize beyond the data it was trained on. Then, within each of the train and test folders, there exist two folders, "benign" and "malignant", that contain images of skin lesions that were professionally verified/classified under those labels, so we can assume that they are "ground-truth" data that the model can learn from.

Subsequently, I conducted a quick exploratory data analysis to visualize the class distribution of the train dataset (the number of images belonging to each of the malignant and benign folders). As seen in train.ipynb, there are slightly more classes that belong to the benign class. However, since the difference is not significant, we decided to not modify the structure of the data or delete any images. The next step for preprocessing was loading in the images into a Tensorflow Keras ImageDataGenerator class, which stored the images in a format compatible for our convolutional neural network (image classification models) to train on down the line. This ImageDataGenerator was also useful because it let us apply data augmentation techniques that essentially applied random transformations to an image such as rotations, shears, skews, brightness adjustments, flips, etc. In turn, we were able to diversify our dataset and thus improve our model's real-world generalizability to a wide variety of images that look different from what our dataset provided us. Furthermore, the ImageDataGenerator also ensured that all images within the imported dataset were standardized to 224x224, the customary/preferred set of dimensions for most transfer learning/ML models in general. Lastly, we also specified the batch_size in this stage, which essentially determines how many loads the model will process the images in during 1 round of training. We settled on a batch size of 32, as that is what we found to be customary and most successful.

Finally, I plotted a sample batch of images from the ImageDataGenerator to visualize the augmented, preprocessed images before proceeding to the model training phase.

# # Phase 2
Within Phase 2, our first step was defining our convolutional neural network (CNN)'s architecture (see build_cnn() in our code for this step). Due to the efficacy of transfer learning, a concept whereby pre-trained weights from state-of-the-art models are transferred to a new model, we decided to leverage this technique in our project to maximize our model's accuracy. It is also a technique ordinarily used in ML projects. Due to time constraints, we only experimented with what are (arguably) the best CNN transfer learning models: ResNet, EfficientNet, MobileNet, and DenseNet families. Within each family, we ran multiple experiments (for a combined total of 8) with different model versions, ultimately finding DenseNet169 as the most performant model with a diagnostic accuracy of 87.12%--a metric comparable to human/doctor-level performance. This was even more impressive considering that 90.9% was the highest accuracy achieved by the other 100+ machine learning enthusiasts who attempted the same classification task on the same Kaggle dataset as us. Lastly, we should mention that we also trained 3 other models for classifying melanoma vs seborrheic keratosis (two different types of skin cancers) based on a separate dataset in the case that the CNN's diagnosis was malignant, but those three models' accuracies weren't high enough to reliably generalize to unseen data.
For each different model, we would "freeze" the pre-trained weights and build off the output of the transfer learning model's base layers, adding our own modifications for pooling, regularization, and fully connected, and output layers. After determining DenseNet169 as the optimal transfer learning model for our classification task, we tried to further tune the model by adding Batch Normalization, Dropout, and additional layers with a regularizing effect to reduce any potential adverse effects of overfitting on our testing accuracy.

It's also worth noting for specification purposes that we trained each model with the Adam optimizer (considered the state-of-the-art optimizer), a binary cross-entropy loss function (since we only have 2 classes), a model checkpoint callback (to automatically save a model's weights if it achieves a better accuracy), and an early stoppage callback (to stop training if the model's performance isn't improving within a certain number of rounds). Moreover, for each model we trained, we documented their progress (shown in our video) across each round of training with the following metrics: accuracy, precision, recall/sensitivity, and f1-score. The diverse consideration of metrics ensured that we had a comprehensive understanding of our model's efficacy beyond a simple measurement of accuracy (which doesn't really consider false negatives or false positives, for example).

# # Phase 3
In Phase 3 Data Analysis, we expanded upon the aforementioned model evaluation by plotting our algorithm's (which we named CheckSkin50, or CS50) confusion matrix. A confusion matrix is useful because it displays how many false negatives (FN), false positives (FP), true negatives (TN), and true positives (TP) a model has--all in a single table. For context, in our case, a false negative is when the model predicts a skin lesion as benign (negative) when it's actually malignant (positive)--and the same logic applies for the other three terms. Generating a confusion matrix helped our team concretely visualize our model's performance and also better understand what sensitivity (TP/(TP+FN)), precision (TP/(TP+FP)), and f1-score (2 * precision * recall / (precision + recall)) represent. Aside from a confusion matrix, we also generated a basic classification report using the sklearn.metrics module, as well as a precision-recall curve to visualize CheckSkin50's tradeoff between precision and recall at every possible decision threshold. The average precision was subsequently computed to summarize the curve into one quantifiable value by considering all possible decision thresholds.

# # Phase 4
The last phase of SkinCheck involved explanatory machine learning. Because AI is often perceived as a black box where people can only see the input and output of an algorithm, there exists a general stigma about the trustworthiness of an AI model. In SkinCheck, we aim to resolve this lack of transparency and impart patient trust--particularly crucial in a clinical setting--through gradient-weighted class activation maps (Grad-CAM). This visualization is human-interpretable, provides concrete reasoning to both the doctor and patient for the computer’s prediction, and is simple in concept: it's computed using the process outlined by Selvaraju et al in 2016. In essence, it calculates the gradient of a certain class with respect to the CNN's final convolutional layer's activation weights. This output then helps us obtain the class discriminative attribution maps, which can be interpreted as a heatmap where the blue highlighted regions indicate what the model weighted heavily or thought was important when making its final prediction. In terms of our results, the regions of interest (RoIs) localized by CheckSkin50 for malignant lesions were focused on specific regions within the lesion that are correlated with malignant tumors, whereas RoIs for benign lesions were generally diffused. In some cases, RoIs for benign images were non-existent altogether, and in other cases, focused on features indicative of benign lesions. In light of these logical findings, we concluded that our overall implementation of Grad-CAM was successful.
