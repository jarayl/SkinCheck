# -*- coding: utf-8 -*-
"""inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16y3kExfyNyUylQQG4HDzoYm3wPOy-d5k
"""

# General Python/ML libraries
import tensorflow as tf
import numpy as np
import cv2

# Specific ML models/packages
from tensorflow.keras.models import Model
from tensorflow.keras.saving import load_model
from tensorflow.image import resize

import tensorflow.keras.backend as K
from tensorflow import GradientTape

# Image-related parameters
CHANNELS = 3
RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT = 300, 300
DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT = 224, 224
TARGET_SIZE = (DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT)
INPUT_SHAPE = (DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT, CHANNELS)

PERCENTAGE_FACTOR = 100;
PERCENT_CONFIDENCE_TRUNCATION = 5
CLASS_THRESHOLD = 0.5

CLASSES = ['benign', 'malignant']

def grad_CAM(model, img, intensity_factor):
    with GradientTape() as tape:
        # ResNet-50V2 had the most accurate/precise visualizations for Grad-CAM
        last_conv_layer = model.get_layer('conv5_block3_out')
        iterate = Model([model.inputs], [model.output, last_conv_layer.output])
        model_out, last_conv_layer = iterate(img.reshape(1, RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT, CHANNELS))
        class_out = model_out[:, np.argmax(model_out[0])]
        grads = tape.gradient(class_out, last_conv_layer)
        pooled_grads = K.mean(grads, axis=(0, 1, 2))

    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)
    heatmap = np.maximum(heatmap, 0)
    np.seterr(divide='ignore', invalid='ignore')
    heatmap /= np.max(heatmap)
    heatmap = heatmap.reshape(10, 10)

    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    colormap = cv2.applyColorMap(np.uint8(heatmap * 255), cv2.COLORMAP_JET)

    dimmed_heatmap = colormap * intensity_factor
    superimposed_img = ((dimmed_heatmap + img) * 180).astype(np.uint8)

    return superimposed_img

def make_inference(diagnosis_model, grad_cam_model, img_array):
    densenet_resized_img = np.asarray(resize(img_array, TARGET_SIZE)).astype(np.uint8)
    np.seterr(divide='ignore', invalid='ignore')
    densenet_resized_img = densenet_resized_img / 255

    testing_img = densenet_resized_img.reshape(1, DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT, CHANNELS)
    prediction = diagnosis_model.predict(testing_img)[0][0]

    # Benign diagnosis
    if prediction < CLASS_THRESHOLD:
        network_prediction = CLASSES[0]
        network_percent_confidence = str((1 - prediction) * PERCENTAGE_FACTOR)[:PERCENT_CONFIDENCE_TRUNCATION]

    # Malignant diagnosis
    else:
        network_prediction = CLASSES[1]
        network_percent_confidence = str(prediction * PERCENTAGE_FACTOR)[:PERCENT_CONFIDENCE_TRUNCATION]

    grad_cam_resized_img = np.asarray(resize(densenet_resized_img, (RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT)))
    superimposed_img = grad_CAM(model=grad_cam_model, img=grad_cam_resized_img, intensity_factor=0.0015)

    # Convert grad_cam_resized_img back into a standard image (with pixel values ranging from 0 - 255)
    grad_cam_resized_img = grad_cam_resized_img * 255
    return grad_cam_resized_img, superimposed_img, network_prediction, network_percent_confidence