# -*- coding: utf-8 -*-
"""Benign-Malignant.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vH23f_lS_E30jDxVnnj-PRi0Bs2NuSQd
"""

# General Python/ML libraries
import tensorflow as tf
import os
from pathlib import Path
import csv
import datetime
import numpy as np
import matplotlib.pyplot as plt
import cv2

# Specific ML models/packages
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.applications import DenseNet169
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras import regularizers
from tensorflow.keras.saving import load_model
from tensorflow.image import resize

import tensorflow.keras.backend as K
from tensorflow import GradientTape


# Image-related parameters
CHANNELS = 3
COLOR_MODE = 'rgb'
RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT = 300, 300
DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT = 224, 224
TARGET_SIZE = (DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT)
INPUT_SHAPE = (DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT, CHANNELS)

# Early stopping hyperparameters
LEARNING_RATE = 0.001
MOMENTUM = 0.99
EPSILON = 0.001
MIN_DELTA = 1e-5
PATIENCE = 12
BATCH_SIZE = 32

# Num rounds to train the model for
EPOCHS = 30

METRICS = ['accuracy',
           Precision(name='precision'),
           Recall(name='recall')]

PERCENTAGE_FACTOR = 100;
PERCENT_CONFIDENCE_TRUNCATION = 5
CLASS_THRESHOLD = 0.5

PLT_SETTINGS = {'family': 'DejaVu Sans',
                'weight': 'heavy',
                'size'  :  11}



# sub_folders = [os.path.join(train_dir, dir) for dir in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, dir))]

# # Count num images in each subfolder
# counts = [0] * len(sub_folders)
# for i, folder in enumerate(sub_folders):
#     counts[i] = len(os.listdir(folder))

# # Bar chart to visualize class distribution
# plt.bar(['benign', 'malignant'], counts)
# plt.xticks(rotation=45)
# plt.ylabel("Number of Images")
# plt.show()

def visualize_augmentations(img_data_generator):
    batch = img_data_generator.next()
    image_batch = batch[0]
    batch_labels = batch[1]
    batch_length = len(image_batch)

    fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(24, 14), constrained_layout=True)

    for i, image in enumerate(image_batch):
        if int(batch_labels[i]) == 0:
            title = 'benign'
        else:
            title = 'malignant'

        if i < (1 / 4) * batch_length:
            axs[0, i].imshow(image_batch[i])
            axs[0, i].set_title(title, fontdict=PLT_SETTINGS)
        elif i < (2 / 4) * batch_length:
            axs[1, i - 8].imshow(image_batch[i])
            axs[1, i - 8].set_title(title, fontdict=PLT_SETTINGS)
        elif i < (3 / 4) * batch_length:
            axs[2, i - 16].imshow(image_batch[i])
            axs[2, i - 16].set_title(title, fontdict=PLT_SETTINGS)
        else:
            axs[3, i - 24].imshow(image_batch[i])
            axs[3, i - 24].set_title(title, fontdict=PLT_SETTINGS)

    plt.show()

# training_data_gen = ImageDataGenerator(rescale=1./255,              # Simplify pixel values to be 0-1
#                                        horizontal_flip=True,        # Randomly flip images horizontally
#                                        zoom_range=0.1,              # Randomly zoom
#                                        shear_range=0.05,            # Shear angle in counter-clockwise direction
#                                        rotation_range=5,            # Randomly rotate
#                                        width_shift_range=0.03,      # Randomly shift the image left/right
#                                        height_shift_range=0.03,     # Randomly shift the image up/down
#                                        fill_mode='constant',        # Filling mode for points outside boundaries
#                                        cval=60,                     # Value used for points outside the boundaries
#                                        brightness_range=(0.9, 1.1)) # Randomly adjust the brightness

# testing_data_gen = ImageDataGenerator(rescale=1./255)

# train_gen = training_data_gen.flow_from_directory(train_dir,
#                                                   color_mode=COLOR_MODE,
#                                                   target_size=TARGET_SIZE,
#                                                   class_mode='binary',
#                                                   batch_size=BATCH_SIZE,
#                                                   shuffle=True)

# test_gen = testing_data_gen.flow_from_directory(test_dir,
#                                                 color_mode=COLOR_MODE,
#                                                 target_size=TARGET_SIZE,
#                                                 class_mode='binary',
#                                                 batch_size=BATCH_SIZE,
#                                                 shuffle=True)

# print('Sample train images:')
# visualize_augmentations(train_gen)

# print('\nSample test images:')
# visualize_augmentations(test_gen)

def create_model(print_summary=False):
    # Instantiate a base model with pre-trained weights
    base_model = ResNet50V2(weights='imagenet',
                            include_top=False,
                            input_shape=INPUT_SHAPE)
    # Freeze the base model
    for layer in base_model.layers:
        layer.trainable = False

    x = base_model.output

    # Add new layers to the end of the base model
    x = GlobalAveragePooling2D()(x)
    # x = BatchNormalization()(x)
    # x = Flatten()(x)
    # x = Dense(512, kernel_regularizer=regularizers.l2(l= 0.016), activity_regularizer=regularizers.l1(0.006),bias_regularizer=regularizers.l1(0.006), activation='relu')(x)
    # x = Dropout(rate=0.45, seed=123)(x)
    x = Dense(512, activation='relu')(x)

    # Add a final dense layer with a single neuron (logistic regression)
    predictions = Dense(1, activation="sigmoid")(x)

    model = Model(inputs=base_model.inputs, outputs=predictions)

    if print_summary:
        model.summary()

    return model

def compile_model(model):
    model.compile(loss='binary_crossentropy',
                  optimizer=Adam(learning_rate=LEARNING_RATE),
                  metrics=METRICS)

def fit_model(model):
    # checkpoint_cb = ModelCheckpoint(checkpoint_filepath,
    #                                 monitor='val_accuracy',
    #                                 mode='max',
    #                                 save_best_only=True)

    # early_stopping_cb = EarlyStopping(monitor='val_accuracy',
    #                                   min_delta=MIN_DELTA,
    #                                   patience=PATIENCE,
    #                                   mode='max',
    #                                   restore_best_weights=True)

    # callbacks = [checkpoint_cb, early_stopping_cb]

    # history = model.fit(train_gen,
    #                     epochs=EPOCHS,
    #                     steps_per_epoch=(train_gen.n/BATCH_SIZE),
    #                     validation_data=test_gen,
    #                     validation_steps=(test_gen.n/BATCH_SIZE),
    #                     callbacks=callbacks)

    history = model.fit(train_gen,
                        epochs=EPOCHS,
                        steps_per_epoch=(train_gen.n/BATCH_SIZE),
                        validation_data=test_gen,
                        validation_steps=(test_gen.n/BATCH_SIZE))

    # Update weights that may have been further tuned during training
    # model.load_weights(checkpoint_filepath)

    return history

def evaluate_model(history):
    fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(30, 4), constrained_layout=True)

    # I hand calculated F1-score since tfa's caused errors
    f1_scores = []
    # calculate f1-score from precision and recall
    for i in range(len(history.history['val_recall'])):
        if history.history['val_precision'][i] != 0 and history.history['val_recall'][i] != 0:
            f1_scores.append((2 * history.history['val_precision'][i] * history.history['val_recall'][i]) / (history.history['val_precision'][i] + history.history['val_recall'][i]))

    for i, metric in enumerate(['accuracy', 'loss', 'precision', 'recall']):
        axs[i].plot(history.history[metric])
        axs[i].plot(history.history['val_' + metric])
        axs[i].set_title('Model {}'.format(metric.capitalize()))
        axs[i].set_xlabel('Epochs')
        axs[i].set_ylabel(metric.capitalize())
        axs[i].legend(['Training', 'Validation'])

        if metric != 'loss':
            non_zeros = [num for num in history.history['val_' + metric] if num != 0]
            avg = "{:.4f}".format(np.mean(non_zeros))
            std = "{:.4f}".format(np.std(non_zeros))
            se = "{:.4f}".format(float(std) / (test_gen.n) ** 0.5)
            print(metric + ': {} ± {}'.format(avg, se))

    # print f1-score
    f1_score = "{:.4f}".format(f1_scores[-1])
    avg = "{:.4f}".format(np.mean(f1_scores))
    std = "{:.4f}".format(np.std(f1_scores))
    se = "{:.4f}".format(float(std) / (test_gen.n) ** 0.5)
    print('final f1-score: ' + f1_score)
    print('f1-score' + ': {} ± {}'.format(avg, se))

# model = create_model(print_summary=True)
# compile_model(model)

# history = fit_model(model)

# model.save(model_filepath)
# model.save(eb7_model_filepath)
# model.save(resnet50_model_filepath)
# model.save(eb5_model_filepath)
# model.save(densenet201_mod_v3_model_filepath)

# evaluate_model(history)

# model = load_model(densenet169_model_filepath)
# model = load_model(resnet50v2_model_filepath)

# create_model(print_summary=True)

def grad_CAM(model, orig_img, intensity_factor):
    with GradientTape() as tape:
        # ResNet-50V2 - best visualizations for Grad-CAM
        last_conv_layer = model.get_layer('conv5_block3_out')
        iterate = Model([model.inputs], [model.output, last_conv_layer.output])
        model_out, last_conv_layer = iterate(orig_img.reshape(1, RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT, CHANNELS))
        class_out = model_out[:, np.argmax(model_out[0])]
        grads = tape.gradient(class_out, last_conv_layer)
        pooled_grads = K.mean(grads, axis=(0, 1, 2))

    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)
    heatmap = np.maximum(heatmap, 0)
    np.seterr(divide='ignore', invalid='ignore')
    heatmap /= np.max(heatmap)
    heatmap = heatmap.reshape(10, 10)

    heatmap = cv2.resize(heatmap, (orig_img.shape[1], orig_img.shape[0]))
    colormap = cv2.applyColorMap(np.uint8(heatmap * 255), cv2.COLORMAP_JET)

    dimmed_heatmap = colormap * intensity_factor
    superimposed_img = ((dimmed_heatmap + orig_img) * 180).astype(np.uint8)

    return superimposed_img

def make_inference(diagnosis_model, grad_cam_model, img_array):
    # disclaimer = '*** DISCLAIMER ***\n' \
    #          'Do not rely on this prediction for self-diagnosis. ' \
    #          'Please check with your local authority services for ' \
    #          'seeking medical assistance.'

    # plt.text(0, 0.5,
    #         disclaimer,
    #         size=15,
    #         ha="center", va="center",
    #         bbox=dict(boxstyle="round",
    #                   ec=(1., 0., 0.),
    #                   fc=(1., 0.9, 0.9)))
    # plt.axis('off')

    densenet_resized_img = np.asarray(resize(img_array, TARGET_SIZE)).astype(np.uint8)
    np.seterr(divide='ignore', invalid='ignore')
    densenet_resized_img = densenet_resized_img / 255

    testing_img = densenet_resized_img.reshape(1, DENSENET169_IMG_WIDTH, DENSENET169_IMG_HEIGHT, CHANNELS)
    prediction = diagnosis_model.predict(testing_img)[0][0]

    # Benign diagnosis
    if prediction < CLASS_THRESHOLD:
        network_prediction = 'BENIGN'
        network_percent_confidence = str((1 - prediction) * PERCENTAGE_FACTOR)[:PERCENT_CONFIDENCE_TRUNCATION]

    # Malignant diagnosis
    else:
        network_prediction = 'MALIGNANT'
        network_percent_confidence = str(prediction * PERCENTAGE_FACTOR)[:PERCENT_CONFIDENCE_TRUNCATION]

    # print('Network Prediction:', network_prediction)
    # plt.title(f'{network_prediction} ({network_percent_confidence}% match)')
    # print(f'{network_prediction} ({network_percent_confidence}% match)')


    grad_cam_resized_img = np.asarray(resize(densenet_resized_img, (RESNET50V2_IMG_WIDTH, RESNET50V2_IMG_HEIGHT)))
    superimposed_img = grad_CAM(model=grad_cam_model, orig_img=grad_cam_resized_img, intensity_factor=0.0015)

    # Convert grad_cam_resized_img back into a standard image (with pixel values ranging from 0 - 255)
    # cv2 (OpenCV) uses BGR whereas Matplotlib uses RGB, need to convert back into RGB so image displays properly
    grad_cam_resized_img = grad_cam_resized_img * 255
    return grad_cam_resized_img, superimposed_img, network_prediction, network_percent_confidence

#@title Sample Diagnostic Test {run: "auto", vertical-output: true}

# batch = test_gen.next()
# image_batch = batch[0]
# batch_labels = batch[1]

# 32 represents the batch size
# image_index = 16 #@param {type:"slider", min:1, max:32, step:1}

# # testing_image = (image_batch[image_index - 1] * 255).astype(np.uint8)
# test_img_fp = r'/content/drive/MyDrive/Colab Notebooks/SkinCheck/benign_samples/1042.jpg'
# testing_image = cv2.imread(test_img_fp).astype(np.uint8)
# # cv2 (OpenCV) uses BGR whereas Matplotlib uses RGB, need to convert back into RGB so image displays properly
# testing_image = cv2.cvtColor(testing_image, cv2.COLOR_BGR2RGB)


# true_label = int(batch_labels[image_index - 1])
# if true_label == 0:
#   print('True Label:', 'BENIGN')
# else:
#   print('True Label:', 'MALIGNANT')

# make_inference(model=model, img_array=testing_image)